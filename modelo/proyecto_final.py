# -*- coding: utf-8 -*-
"""proyecto_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQd_H18syUzgZg2_vRmUI_oBGp2xmiw3

________________________________________________________________________________
UNIVERSIDAD AUTÓNOMA DE CHIHUAHUA

FACULTAD DE INGENIERÍA

MAESTRÍA EN INGENIERÍA EN COMPUTACIÓN

MATERIA: MACHINE LEARNING

DOCENTE: OLANDA PRIETO ORDAZ

PROYECTO FINAL DE LA MATERIA

ALUMNO: HEBER ABRAHAM ZAPATA ROBLES

MATRÍCULA: 329454
________________________________________________________________________________
"""

'''
Importar librerías necesarias
'''
# librerias para manipular datos y visualizarlos
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# librerias para preprocesamiento de datos
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
# librerias de los moedlos usados
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
# librerias para métricas
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, fbeta_score
# libreria para guardar modelos
import joblib

'''
Ingesta de datos
'''
ruta = "C:/Users/heber/Downloads/oasis_longitudinal_demographics-8d83e569fa2e2d30 (1).xlsx"
# dataset para el dataset_150
oasis = pd.read_excel (ruta)
# dataset para el dataset_373
oasis_copy = oasis.copy()

'''
Preparar datos
'''
# funcion para preparar los datos
def preparar_datos(oasis):
    # eliminar columnas innecesarias
    columnas_innecesarias = ['Subject ID', 'MRI ID', 'Visit', 'Hand']
    oasis_preparado = oasis.drop(columns=columnas_innecesarias)
    # Converted a Demented en la columna Group
    oasis_preparado['Group'] = oasis_preparado['Group'].replace('Converted', 'Demented')
    # Mapear las clases Nondemented a 0 y Demented a 1
    mapeo = {'Nondemented': 0, 'Demented': 1}
    oasis_preparado['Group'] = oasis_preparado['Group'].map(mapeo)
    return oasis_preparado
# funcion para preparar el dataset de 150 pacientes
def oasis_150 (oasis):
    # seleccionar la visita 1
    oasis_select = oasis.loc[oasis['Visit'] == 1].reset_index(drop=True)
    return oasis_select

'''
Creación del dataset_150
'''
# preparar el dataset
oasis_new = oasis_150 (oasis)
oasis_new = preparar_datos(oasis_new)
# columnas categóricas y numéricas
categorical_features = ['M/F']
numeric_features = oasis_new.drop(columns=['M/F', 'Group']).columns
# preprocesador para transformar las columnas categóricas y numéricas
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numeric_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)
    ])
# dividir target y características
X_150 = oasis_new.drop(columns='Group')
y_150 = oasis_new['Group']
# separación del dataset, manteniendo la proporción del target
X_train, X_test, y_150_train, y_150_test = train_test_split(X_150, y_150, test_size=0.2, random_state=42, stratify=y_150)
# aplicar el pipeline al conjunto de entrenamiento
X_150_train = preprocessor.fit_transform(X_train)
X_150_test = preprocessor.transform(X_test)
# verificar la separacion
# set entrenamiento
train_class_distribution = pd.Series(y_150_train).value_counts(normalize=True)
print("Distribución de clases en el conjunto de entrenamiento:")
print(train_class_distribution)
# set prueba
test_class_distribution = pd.Series(y_150_test).value_counts(normalize=True)
print("\nDistribución de clases en el conjunto de prueba:")
print(test_class_distribution)

'''
Creación del dataset_150
'''
# preparar el dataset
oasis_new = oasis_150 (oasis)
oasis_new = preparar_datos(oasis_new)
# columnas categóricas y numéricas
categorical_features = ['M/F']
numeric_features = oasis_new.drop(columns=['M/F', 'Group']).columns

# preprocesador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numeric_features),
        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
    ])

# dividir características y target
X_150 = oasis_new.drop(columns='Group')
y_150 = oasis_new['Group']

# división del conjunto de datos
X_train, X_test, y_150_train, y_150_test = train_test_split(X_150, y_150, test_size=0.2, random_state=42, stratify=y_150)

# aplicar el pipeline
X_150_train = preprocessor.fit_transform(X_train)
X_150_test = preprocessor.transform(X_test)

# verificar la distribución de clases
print("Distribución de clases en el conjunto de entrenamiento:")
print(pd.Series(y_150_train).value_counts(normalize=True))

print("\nDistribución de clases en el conjunto de prueba:")
print(pd.Series(y_150_test).value_counts(normalize=True))

'''
Regresión logística
'''
# modelo
modelo = LogisticRegression()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'penalty': ['l1', 'l2'],
              'solver': ['liblinear', 'saga'],
              'max_iter': [1000, 5000, 10000, 15000]}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_150_train, y_150_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_150_test)
# métricas
accuracy = accuracy_score(y_150_test, y_pred)
precision = precision_score(y_150_test, y_pred)
recall = recall_score(y_150_test, y_pred)
f1 = f1_score(y_150_test, y_pred)
fbeta = fbeta_score(y_150_test, y_pred, beta=2)
# reporte
print("Regresión logística:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_150_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_150_test, y_pred)
print("\nReporte de clasificación:")
print(report)
# guardar el mejor modelo en un archivo .pkl
joblib.dump(mejor_modelo, 'best_lr_model_150.pkl')

'''
SVM
'''
# modelo
modelo = SVC()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'C': [0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'degree': [2, 3, 4],
              'gamma': ['scale', 'auto']}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_150_train, y_150_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_150_test)
# métricas
accuracy = accuracy_score(y_150_test, y_pred)
precision = precision_score(y_150_test, y_pred)
recall = recall_score(y_150_test, y_pred)
f1 = f1_score(y_150_test, y_pred)
fbeta = fbeta_score(y_150_test, y_pred, beta=2)
# reporte
print("SVM:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_150_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_150_test, y_pred)
print("\nReporte de clasificación:")
print(report)
# guardar el mejor modelo en un archivo .pkl
joblib.dump(mejor_modelo, 'best_svm_model_150.pkl')

'''
Random Forest
'''
# modelo
modelo = RandomForestClassifier()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'n_estimators': [100, 200, 300],
              'criterion': ['gini', 'entropy'],
              'max_depth': [None, 10, 20, 30],
              'max_features': [None, 'sqrt', 'log2']}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_150_train, y_150_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_150_test)
# métricas
accuracy = accuracy_score(y_150_test, y_pred)
precision = precision_score(y_150_test, y_pred)
recall = recall_score(y_150_test, y_pred)
f1 = f1_score(y_150_test, y_pred)
fbeta = fbeta_score(y_150_test, y_pred, beta=2)
# reporte
print("Random Forest:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_150_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_150_test, y_pred)
print("\nReporte de clasificación:")
print(report)
# guardar el mejor modelo en un archivo .pkl
joblib.dump(mejor_modelo, 'best_rf_model_150.pkl')

'''
Creación del dataset_373
'''
# preparar el dataset
oasis_copy = preparar_datos(oasis_copy)

# columnas categóricas y numéricas
categorical_features = ['M/F']
numeric_features = oasis_copy.drop(columns=['M/F', 'Group']).columns

# preprocesador para transformar las columnas categóricas y numéricas
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numeric_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)
    ])

# dividir target y características
X_373 = oasis_copy.drop(columns='Group')
y_373 = oasis_copy['Group']

# separación del dataset, manteniendo la proporción del target
X_train, X_test, y_373_train, y_373_test = train_test_split(
    X_373, y_373, test_size=0.2, random_state=42, stratify=y_373)

# aplicar el pipeline al conjunto de entrenamiento
X_373_train = preprocessor.fit_transform(X_train)
# guardar pipeline
joblib.dump(preprocessor, 'pipeline_373.pkl')
X_373_test = preprocessor.transform(X_test)

# verificar la separacion
# set entrenamiento
train_class_distribution = pd.Series(y_373_train).value_counts(normalize=True)
print("Distribución de clases en el conjunto de entrenamiento:")
print(train_class_distribution)

# set prueba
test_class_distribution = pd.Series(y_373_test).value_counts(normalize=True)
print("\nDistribución de clases en el conjunto de prueba:")
print(test_class_distribution)

'''
Regresión logística
'''
# modelo
modelo = LogisticRegression()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'penalty': ['l1', 'l2'],
              'solver': ['liblinear', 'saga'],
              'max_iter': [1000, 5000, 10000, 15000]}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_373_train, y_373_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_373_test)
# métricas
accuracy = accuracy_score(y_373_test, y_pred)
precision = precision_score(y_373_test, y_pred)
recall = recall_score(y_373_test, y_pred)
f1 = f1_score(y_373_test, y_pred)
fbeta = fbeta_score(y_373_test, y_pred, beta=2)
# reporte
print("Regresión logística:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_373_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_373_test, y_pred)
print("\nReporte de clasificación:")
print(report)
# guardar el mejor modelo en un archivo .pkl
joblib.dump(mejor_modelo, 'best_lr_model_373.pkl')

'''
SVM
'''
# modelo
modelo = SVC()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'C': [0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'degree': [2, 3, 4],
              'gamma': ['scale', 'auto']}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_373_train, y_373_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_373_test)
# métricas
accuracy = accuracy_score(y_373_test, y_pred)
precision = precision_score(y_373_test, y_pred)
recall = recall_score(y_373_test, y_pred)
f1 = f1_score(y_373_test, y_pred)
fbeta = fbeta_score(y_373_test, y_pred, beta=2)
# reporte
print("SVM:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_373_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_373_test, y_pred)
print("\nReporte de clasificación:")
print(report)
joblib.dump(mejor_modelo, 'best_svm_model_373.pkl')

'''
Random Forest
'''
# modelo
modelo = RandomForestClassifier()
# kfold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# grid
param_grid = {'n_estimators': [100, 200, 300],
              'criterion': ['gini', 'entropy'],
              'max_depth': [None, 10, 20, 30],
              'max_features': [None, 'sqrt', 'log2']}
# grid search
grid_search = GridSearchCV(modelo, param_grid, cv=kfold, scoring='accuracy')
# entrenamiento
grid_search.fit(X_373_train, y_373_train)
# mejores parámetros
mejores_parametros = grid_search.best_params_
print ("Mejores parámetros:", mejores_parametros)
# mejor modelo
mejor_modelo = grid_search.best_estimator_
# predicciones
y_pred = mejor_modelo.predict(X_373_test)
# métricas
accuracy = accuracy_score(y_373_test, y_pred)
precision = precision_score(y_373_test, y_pred)
recall = recall_score(y_373_test, y_pred)
f1 = f1_score(y_373_test, y_pred)
fbeta = fbeta_score(y_373_test, y_pred, beta=2)
# reporte
print("Random Forest:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1:", f1)
print("Fbeta:", fbeta)
# matriz de confusión
confusion = confusion_matrix(y_373_test, y_pred)
print("\nMatriz de confusión:")
print(confusion)
# plot matriz de confusión
sns.heatmap(confusion, annot=True, fmt='d')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.show()
# reporte de clasificación
report = classification_report(y_373_test, y_pred)
print("\nReporte de clasificación:")
print(report)
joblib.dump(mejor_modelo, 'best_rf_model_373.pkl')